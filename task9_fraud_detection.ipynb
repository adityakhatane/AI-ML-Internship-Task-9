{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4696cef",
   "metadata": {},
   "source": [
    "# Task 9: Credit Card Fraud Detection\n",
    "\n",
    "Random Forest & Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea3a07",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dceac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faee70e",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7320aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trans_date_trans_time</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_pop</th>\n",
       "      <th>job</th>\n",
       "      <th>dob</th>\n",
       "      <th>trans_num</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-01-2019 00:58</td>\n",
       "      <td>\"Stokes, Christiansen and Sipes\"</td>\n",
       "      <td>grocery_net</td>\n",
       "      <td>14.37</td>\n",
       "      <td>Wales</td>\n",
       "      <td>AK</td>\n",
       "      <td>64.7556</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Administrator, education\"</td>\n",
       "      <td>09-11-1939</td>\n",
       "      <td>a3806e984cec6ac0096d8184c64ad3a1</td>\n",
       "      <td>65.654142</td>\n",
       "      <td>-164.722603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-01-2019 15:06</td>\n",
       "      <td>Predovic Inc</td>\n",
       "      <td>shopping_net</td>\n",
       "      <td>966.11</td>\n",
       "      <td>Wales</td>\n",
       "      <td>AK</td>\n",
       "      <td>64.7556</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Administrator, education\"</td>\n",
       "      <td>09-11-1939</td>\n",
       "      <td>a59185fe1b9ccf21323f581d7477573f</td>\n",
       "      <td>65.468863</td>\n",
       "      <td>-165.473127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-01-2019 22:37</td>\n",
       "      <td>Wisozk and Sons</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>49.61</td>\n",
       "      <td>Wales</td>\n",
       "      <td>AK</td>\n",
       "      <td>64.7556</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Administrator, education\"</td>\n",
       "      <td>09-11-1939</td>\n",
       "      <td>86ba3a888b42cd3925881fa34177b4e0</td>\n",
       "      <td>65.347667</td>\n",
       "      <td>-165.914542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-01-2019 23:06</td>\n",
       "      <td>Murray-Smitham</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>295.26</td>\n",
       "      <td>Wales</td>\n",
       "      <td>AK</td>\n",
       "      <td>64.7556</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Administrator, education\"</td>\n",
       "      <td>09-11-1939</td>\n",
       "      <td>3a068fe1d856f0ecedbed33e4b5f4496</td>\n",
       "      <td>64.445035</td>\n",
       "      <td>-166.080207</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-01-2019 23:59</td>\n",
       "      <td>Friesen Lt</td>\n",
       "      <td>health_fitness</td>\n",
       "      <td>18.17</td>\n",
       "      <td>Wales</td>\n",
       "      <td>AK</td>\n",
       "      <td>64.7556</td>\n",
       "      <td>-165.6723</td>\n",
       "      <td>145</td>\n",
       "      <td>\"Administrator, education\"</td>\n",
       "      <td>09-11-1939</td>\n",
       "      <td>891cdd1191028759dc20dc224347a0ff</td>\n",
       "      <td>65.447094</td>\n",
       "      <td>-165.446843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trans_date_trans_time                          merchant        category  \\\n",
       "0      04-01-2019 00:58  \"Stokes, Christiansen and Sipes\"     grocery_net   \n",
       "1      04-01-2019 15:06                      Predovic Inc    shopping_net   \n",
       "2      04-01-2019 22:37                   Wisozk and Sons        misc_pos   \n",
       "3      04-01-2019 23:06                    Murray-Smitham     grocery_pos   \n",
       "4      04-01-2019 23:59                        Friesen Lt  health_fitness   \n",
       "\n",
       "      amt   city state      lat      long  city_pop  \\\n",
       "0   14.37  Wales    AK  64.7556 -165.6723       145   \n",
       "1  966.11  Wales    AK  64.7556 -165.6723       145   \n",
       "2   49.61  Wales    AK  64.7556 -165.6723       145   \n",
       "3  295.26  Wales    AK  64.7556 -165.6723       145   \n",
       "4   18.17  Wales    AK  64.7556 -165.6723       145   \n",
       "\n",
       "                          job         dob                         trans_num  \\\n",
       "0  \"Administrator, education\"  09-11-1939  a3806e984cec6ac0096d8184c64ad3a1   \n",
       "1  \"Administrator, education\"  09-11-1939  a59185fe1b9ccf21323f581d7477573f   \n",
       "2  \"Administrator, education\"  09-11-1939  86ba3a888b42cd3925881fa34177b4e0   \n",
       "3  \"Administrator, education\"  09-11-1939  3a068fe1d856f0ecedbed33e4b5f4496   \n",
       "4  \"Administrator, education\"  09-11-1939  891cdd1191028759dc20dc224347a0ff   \n",
       "\n",
       "   merch_lat  merch_long is_fraud  \n",
       "0  65.654142 -164.722603        1  \n",
       "1  65.468863 -165.473127        1  \n",
       "2  65.347667 -165.914542        1  \n",
       "3  64.445035 -166.080207        1  \n",
       "4  65.447094 -165.446843        1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"fraud_data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e5abbd",
   "metadata": {},
   "source": [
    "## 3. Clean Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66383b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14446 entries, 0 to 14445\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   trans_date_trans_time  14446 non-null  object \n",
      " 1   merchant               14446 non-null  object \n",
      " 2   category               14446 non-null  object \n",
      " 3   amt                    14446 non-null  float64\n",
      " 4   city                   14446 non-null  object \n",
      " 5   state                  14446 non-null  object \n",
      " 6   lat                    14446 non-null  float64\n",
      " 7   long                   14446 non-null  float64\n",
      " 8   city_pop               14446 non-null  int64  \n",
      " 9   job                    14446 non-null  object \n",
      " 10  dob                    14446 non-null  object \n",
      " 11  trans_num              14446 non-null  object \n",
      " 12  merch_lat              14446 non-null  float64\n",
      " 13  merch_long             14446 non-null  float64\n",
      " 14  is_fraud               14446 non-null  object \n",
      "dtypes: float64(5), int64(1), object(9)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.columns = df.columns.str.strip().str.lower()\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2abb8b",
   "metadata": {},
   "source": [
    "## 4. Identify Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "192f1811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_fraud\n",
       "0                         12600\n",
       "1                          1844\n",
       "1\"2020-12-24 16:56:24\"        1\n",
       "0\"2019-01-01 00:00:44\"        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Automatically select last column as target (modify if needed)\n",
    "target = df.columns[-1]\n",
    "df[target].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1655c3",
   "metadata": {},
   "source": [
    "## 5. Remove Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a33e4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14446 entries, 0 to 14445\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   amt         14446 non-null  float64\n",
      " 1   lat         14446 non-null  float64\n",
      " 2   long        14446 non-null  float64\n",
      " 3   city_pop    14446 non-null  int64  \n",
      " 4   merch_lat   14446 non-null  float64\n",
      " 5   merch_long  14446 non-null  float64\n",
      " 6   is_fraud    14446 non-null  object \n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 790.1+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove non-numeric feature columns but keep the target column\n",
    "# (some datasets have the target as object dtype, so selecting dtypes on the whole\n",
    "# dataframe can drop it). We build numeric X and then reattach the target.\n",
    "X = df.drop(columns=[target])\n",
    "X = X.select_dtypes(include=[\"number\"])\n",
    "df = pd.concat([X, df[target]], axis=1)\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed74c2e",
   "metadata": {},
   "source": [
    "## 6. Feature-Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bac8e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728fa9af",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3dbb7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a1b04",
   "metadata": {},
   "source": [
    "## 8. Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6d875c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                     0       0.92      0.99      0.96      2504\n",
      "0\"2019-01-01 00:00:44\"       0.00      0.00      0.00         1\n",
      "                     1       0.87      0.48      0.62       385\n",
      "\n",
      "              accuracy                           0.92      2890\n",
      "             macro avg       0.60      0.49      0.52      2890\n",
      "          weighted avg       0.92      0.92      0.91      2890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f71d65e",
   "metadata": {},
   "source": [
    "## 9. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f20017c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "                     0       0.97      0.98      0.98      2504\n",
      "0\"2019-01-01 00:00:44\"       0.00      0.00      0.00         1\n",
      "                     1       0.89      0.78      0.83       385\n",
      "\n",
      "              accuracy                           0.96      2890\n",
      "             macro avg       0.62      0.59      0.60      2890\n",
      "          weighted avg       0.96      0.96      0.96      2890\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875d947",
   "metadata": {},
   "source": [
    "## 10. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3488f8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m precision = \u001b[43mprecision_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_rf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m recall = recall_score(y_test, y_pred_rf, zero_division=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m f1 = f1_score(y_test, y_pred_rf, zero_division=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2524\u001b[39m, in \u001b[36mprecision_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   2356\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   2357\u001b[39m     {\n\u001b[32m   2358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   2383\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2384\u001b[39m ):\n\u001b[32m   2385\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[32m   2386\u001b[39m \n\u001b[32m   2387\u001b[39m \u001b[33;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2522\u001b[39m \u001b[33;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[32m   2523\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2524\u001b[39m     p, _, _, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2525\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2526\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2527\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2528\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2529\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2531\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2532\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2533\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2534\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1996\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1827\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1828\u001b[39m \n\u001b[32m   1829\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1993\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1994\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1995\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1999\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1779\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1777\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1778\u001b[39m             average_options.remove(\u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1780\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m but average=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1781\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (y_type, average_options)\n\u001b[32m   1782\u001b[39m         )\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m1\u001b[39m):\n\u001b[32m   1784\u001b[39m     warnings.warn(\n\u001b[32m   1785\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) is ignored when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1786\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maverage != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m). You may use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "# Choose an averaging method appropriate for binary vs multiclass targets\n",
    "# 'binary' is valid only for binary targets; for multiclass use 'weighted' (or 'macro'/'micro').\n",
    "if len(np.unique(y_test)) == 2:\n",
    "    avg = 'binary'\n",
    "else:\n",
    "    avg = 'weighted'\n",
    "\n",
    "precision = precision_score(y_test, y_pred_rf, zero_division=0, average=avg)\n",
    "recall = recall_score(y_test, y_pred_rf, zero_division=0, average=avg)\n",
    "f1 = f1_score(y_test, y_pred_rf, zero_division=0, average=avg)\n",
    "print('average used:', avg)\n",
    "precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6146c",
   "metadata": {},
   "source": [
    "## 11. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe430e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = rf.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "pd.Series(importances, index=features).nlargest(10).plot(kind='barh')\n",
    "plt.title(\"Top 10 Important Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c1cd86",
   "metadata": {},
   "source": [
    "## 12. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56979a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joblib.dump(rf, \"random_forest_fraud_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54b716",
   "metadata": {},
   "source": [
    "## Final Outcome\n",
    "\n",
    "Random Forest outperformed Logistic Regression and is suitable for fraud detection tasks with imbalanced data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
